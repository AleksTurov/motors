{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec69ad21",
   "metadata": {},
   "source": [
    "# Motor Remaining Useful Life (RUL) Prediction: Baseline Pipeline\n",
    "\n",
    "This notebook demonstrates a baseline approach for predicting the Remaining Useful Life (RUL) of motors using a dataset similar to NASA C-MAPSS. The workflow includes data loading, feature engineering, model training (XGBoost), and evaluation. \n",
    "\n",
    "---\n",
    "\n",
    "**Outline:**\n",
    "1. Import libraries and load data\n",
    "2. Initial data analysis and visualization\n",
    "3. Add RUL target variable\n",
    "4. Aggregate features with rolling window\n",
    "5. Feature engineering: derivatives, rolling stats\n",
    "6. Train/test split\n",
    "7. Baseline XGBoost model\n",
    "8. Model evaluation and error analysis\n",
    "9. (Optional) Data preparation for LSTM/GRU (sliding window)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1c7ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from catboost import CatBoostRegressor\n",
    "from IPython.display import display\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import make_scorer, mean_absolute_error\n",
    "import scipy.stats as st\n",
    "\n",
    "\n",
    "import shap\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(\"Pandas version:\", pd.__version__)\n",
    "print(\"Numpy version:\", np.__version__)\n",
    "np.random.seed(324)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507fcebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('../data/Data.csv')\n",
    "\n",
    "# Display the first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e211ffe",
   "metadata": {},
   "source": [
    "## 1. Initial Data Analysis and Visualization\n",
    "\n",
    "- Check data structure, types, and missing values\n",
    "- Visualize cycle and sensor distributions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda9cf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58f0f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show dataframe info and check for missing values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b036a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nMissing values per column:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cf8aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show basic statistics. Sensors p01 and p00, p07, p09, p10, p16 and p17 are not changed\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e52f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d69fcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns[df.nunique() < 2]) # Identify columns with only one unique value\n",
    "\n",
    "# Drop columns with only one unique value\n",
    "df = df.loc[:, df.nunique() > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681afd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of cycles per motor\n",
    "plt.figure(figsize=(8,4))\n",
    "df.groupby('id')['cycle'].max().hist(bins=50)\n",
    "plt.title('Distribution of Maximum Cycles per Motor')\n",
    "plt.xlabel('Max Cycle')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019dc20f",
   "metadata": {},
   "source": [
    "## 2. Add RUL (Remaining Useful Life) Target Variable\n",
    "\n",
    "- For each motor, calculate RUL as the difference between the maximum cycle and the current cycle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ac7a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate RUL for each row \n",
    "df_target = df.groupby('id')['cycle'].transform('max')\n",
    "\n",
    "df['max_cycle'] = df_target.copy()\n",
    "\n",
    "df['rul'] = df['max_cycle'] - df['cycle']\n",
    "df.drop('max_cycle', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9d5ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ECDF plot for RUL (Remaining Useful Life)\n",
    "#This plot shows the ECDF (Empirical Cumulative Distribution Function) of RUL. \n",
    "# It helps us see the distribution of remaining useful life for all engines.\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.displot(data=df, x='rul', kind='ecdf')\n",
    "plt.title('ECDF of RUL')\n",
    "plt.xlabel('RUL (cycles)')\n",
    "plt.ylabel('Proportion')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6658a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check correlation with RUL. There are p02, p15, p03, p18, p06, p13 that are highly correlated with RUL.\n",
    "# Cycle type features also strongly correlate with RUL (as expected, since RUL = max_cycle - cycle).\n",
    "print(df.corr().abs()['rul'].sort_values(ascending=False))\n",
    "# Plot correlation matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(df.corr(), annot=True, fmt='.2f', cmap='coolwarm', square=True, cbar_kws={\"shrink\": .8})\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ede778d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['p20']) # cor with 'p05'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d36f36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7243956b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column like as the cycle is time series data, so we need to create rolling features\n",
    "\n",
    "# Note: When you create rolling window features, the first (window_size-1) rows for each engine will have NaN values.\n",
    "# This is normal because there is not enough history for the window.\n",
    "# To use PCA or any model that does not support NaN, you should fill these NaN values.\n",
    "# The most common way is to fill NaN with the mean or median of the column.\n",
    "\n",
    "sensor_cols = ['p02', 'p03', 'p04', 'p05', 'p06', 'p08', 'p11', 'p12',\n",
    "       'p13', 'p14', 'p15', 'p17', 'p18', 'p19', 's1', 's2']\n",
    "sensor_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f63a049",
   "metadata": {},
   "source": [
    "## 3. Aggregate Features with Rolling Window\n",
    "\n",
    "- For each motor and each cycle, compute rolling window aggregates (mean, std, min, max) for sensor \n",
    "- This helps capture recent trends and variability for each engine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51491ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column like as the cycle is time series data, so we need to create rolling features\n",
    "\n",
    "# Note: When you create rolling window features, the first (window_size-1) rows for each engine will have NaN values.\n",
    "# This is normal because there is not enough history for the window.\n",
    "# To use PCA or any model that does not support NaN, you should fill these NaN values.\n",
    "# The most common way is to fill NaN with the mean or median of the column.\n",
    "\n",
    "# Add difference features for each sensor column\n",
    "for col in sensor_cols:\n",
    "    df[f'{col}_diff1'] = df.groupby('id')[col].diff()\n",
    "\n",
    "def add_rolling_features(df, cols, window):\n",
    "    \"\"\" \n",
    "    Function to add rolling features for each column in cols\n",
    "    using a specified window size.\n",
    "    \"\"\"\n",
    "    new_features = {}\n",
    "    for func in ['mean', 'std', 'min', 'max']:\n",
    "        for col in cols:\n",
    "            new_features[f'{col}_roll{window}_{func}'] = (\n",
    "                df.groupby('id')[col].transform(lambda x: x.rolling(window, min_periods=1).agg(func))\n",
    "            )\n",
    "    df = pd.concat([df, pd.DataFrame(new_features)], axis=1)\n",
    "    df = df.copy()  # Defragment the DataFrame\n",
    "    # Fill NaN values with the mean of the column\n",
    "    for col in new_features.keys():\n",
    "        df[col] = df[col].fillna(df[col].mean())\n",
    "    return df\n",
    "\n",
    "windows = [5, 10, 20, 30, 45, 60, 90, 120, 180, 350]\n",
    "# Add rolling features for each window size\n",
    "for window in windows:\n",
    "    df = add_rolling_features(df, sensor_cols, window)\n",
    "\n",
    "df[[c for c in df.columns if 'roll' in c]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0de0b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rolling_trend(df, cols, window):\n",
    "    \"\"\"\n",
    "    Function to add rolling trend features for each column in cols\n",
    "    using a specified window size.\n",
    "    The trend is calculated using a linear regression fit (slope).\n",
    "    \n",
    "    \"\"\"\n",
    "    def trend(x):\n",
    "        idx = np.arange(len(x))\n",
    "        if len(x) < 2:\n",
    "            return 0.0\n",
    "        return np.polyfit(idx, x, 1)[0]\n",
    "    new_features = {}\n",
    "    for col in cols:\n",
    "        new_features[f'{col}_roll{window}_trend'] = (\n",
    "            df.groupby('id')[col]\n",
    "              .transform(lambda x: x.rolling(window, min_periods=2).apply(trend, raw=True))\n",
    "        )\n",
    "    df = pd.concat([df, pd.DataFrame(new_features, index=df.index)], axis=1)\n",
    "    df = df.copy()  \n",
    "    return df\n",
    "\n",
    "\n",
    "for w in windows:\n",
    "    df = add_rolling_trend(df, sensor_cols, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f79ac31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "rolling_cols = [c for c in df.columns if 'roll' in c or 'diff1' in c]\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df[rolling_cols] = imputer.fit_transform(df[rolling_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73592ccc",
   "metadata": {},
   "source": [
    "## 5. Train/Test Split\n",
    "\n",
    "- Split the data into training and test sets. We will use the last 20 cycles of each engine as the test set. The rest will be used for training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438fa8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bins for RUL to stratify the split\n",
    "# This helps to ensure that both training and test sets have a similar distribution of RUL values\n",
    "# We use pd.qcut to create quantile-based bins, which helps in stratifying the split\n",
    "# The 'duplicates' parameter is set to 'drop' to avoid issues with bins that have the same edges\n",
    "# This is useful when the RUL values are not evenly distributed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acb8e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bins for RUL to stratify the split\n",
    "id_rul = df.groupby('id')['rul'].max().reset_index()\n",
    "id_rul['rul_bin'] = pd.qcut(id_rul['rul'], q=10, duplicates='drop')\n",
    "id_rul['rul_bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6f0426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets, stratifying by the RUL bins\n",
    "train_ids, test_ids = train_test_split(\n",
    "    id_rul['id'],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=id_rul['rul_bin']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f81133b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form train and test sets based on the selected ids\n",
    "train_df = df[df['id'].isin(train_ids)].copy()\n",
    "test_df = df[df['id'].isin(test_ids)].copy()\n",
    "\n",
    "print(train_df['rul'].describe())\n",
    "print(test_df['rul'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4c28ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the distribution of RUL in train and test sets\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.hist(train_df['rul'], bins=30, alpha=0.5, label='train')\n",
    "plt.hist(test_df['rul'], bins=30, alpha=0.5, label='test')\n",
    "plt.xlabel('RUL')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "plt.title('Train/Test RUL Distribution (no id overlap)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0d7c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ks_2samp\n",
    "\n",
    "stat, p_value = ks_2samp(train_df['rul'], test_df['rul'])\n",
    "print(f\"KS statistic: {stat:.4f}, p-value: {p_value:.4f}\")\n",
    "\n",
    "if p_value > 0.05:\n",
    "    print(\"rul distributions in train and test are statistically similar.\")\n",
    "else:\n",
    "    print(\"rul distributions in train and test are statistically different.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e541b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [col for col in train_df.columns if col not in ['rul', 'id', 'cycle']]\n",
    "X_train = train_df[feature_cols]\n",
    "y_train = train_df['rul']\n",
    "X_test = test_df[feature_cols]\n",
    "y_test = test_df['rul']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed7d9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search and remove features with high correlation (> 0.95)\n",
    "corr_matrix = pd.DataFrame(X_train_scaled, columns=feature_cols).corr().abs()\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
    "print(\"Will be delete features with high correlation:\", to_drop)\n",
    "\n",
    "# Delete from train/test\n",
    "X_train_reduced = pd.DataFrame(X_train_scaled, columns=feature_cols).drop(columns=to_drop)\n",
    "X_test_reduced = pd.DataFrame(X_test_scaled, columns=feature_cols).drop(columns=to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5980d0b8",
   "metadata": {},
   "source": [
    "# 5 LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9609514a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(y_test, y_pred):\n",
    "    # Main metrics\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    print(f\"MAE (all): {mae:.2f}\")\n",
    "    print(f\"RMSE (all): {rmse:.2f}\")\n",
    "\n",
    "    # there are some engines with RUL > 200, so we need to analyze errors by ranges\n",
    "    bins = [0, 60, 100, 200, np.inf]\n",
    "    labels = ['<=60','60-100','100-200', '>200']\n",
    "    y_test_bins = pd.cut(y_test, bins=bins, labels=labels)\n",
    "\n",
    "    for label in labels:\n",
    "        mask = y_test_bins == label\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "        mae_bin = mean_absolute_error(y_test[mask], np.array(y_pred)[mask])\n",
    "        rmse_bin = np.sqrt(mean_squared_error(y_test[mask], np.array(y_pred)[mask]))\n",
    "        print(f\"\\nRange RUL {label}:\")\n",
    "        print(f\"  MAE: {mae_bin:.2f}\")\n",
    "        print(f\"  RMSE: {rmse_bin:.2f}\")\n",
    "\n",
    "    # Visualization\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.scatter(y_test, y_pred, alpha=0.3)\n",
    "    plt.xlabel('True RUL')\n",
    "    plt.ylabel('Predicted RUL')\n",
    "    plt.title('Predicted vs True RUL')\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', color='red')\n",
    "    plt.show()\n",
    "    # Visualize errors for RUL <= 60\n",
    "    mask_short = y_test <= 60\n",
    "    errors = y_test[mask_short] - y_pred[mask_short]\n",
    "\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.hist(errors, bins=40, alpha=0.7)\n",
    "    plt.title('(True RUL - Predicted RUL) for RUL ≤ 60')\n",
    "    plt.xlabel('Error')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.xlim(-60, 30)\n",
    "    # Calculate errors and visualize confidence intervals \n",
    "    \n",
    "    mean_err = np.mean(errors)\n",
    "    sem = st.sem(errors)\n",
    "    plt.axvline(mean_err, color='red', linestyle='--', label='Mean error')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # Weighted MAE\n",
    "    # We consider errors for RUL <= 60 three times more important\n",
    "    weights = np.where(y_test <= 60, 3, 1)  \n",
    "    weighted_mae = np.sum(weights * np.abs(y_test - y_pred)) / np.sum(weights)\n",
    "    print(f\"weighted MAE: {weighted_mae:.2f}\")\n",
    "\n",
    "def plot_feature_importances(model, X_train):\n",
    "    importances = model.feature_importances_\n",
    "    feature_names = X_train.columns\n",
    "\n",
    "    # top 20 most important features\n",
    "    indices = np.argsort(importances)[::-1][:20]\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.title(\"Feature importances (XGBoost)\")\n",
    "    plt.bar(range(len(indices)), importances[indices], align=\"center\")\n",
    "    plt.xticks(range(len(indices)), [feature_names[i] for i in indices], rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_feature_importances_catboost(model, X_train):\n",
    "    importances = model.get_feature_importance()\n",
    "    feature_names = X_train.columns\n",
    "    indices = np.argsort(importances)[::-1][:20]\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.title(\"Feature importances (CatBoost)\")\n",
    "    plt.bar(range(len(indices)), importances[indices], align=\"center\")\n",
    "    plt.xticks(range(len(indices)), [feature_names[i] for i in indices], rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "def plot_shap_values(model, X_test):\n",
    "    explainer = shap.Explainer(model)\n",
    "    shap_values = explainer(X_test)\n",
    "\n",
    "    # Summary plot\n",
    "    shap.summary_plot(shap_values, X_test, max_display=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdd2d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_s_score(rul_true, rul_pred):\n",
    "    \"\"\"\n",
    "    Compute S-score based on the difference between predicted and true RUL.\n",
    "    The S-score is a measure of the accuracy of the RUL predictions.\n",
    "    It penalizes underestimation more than overestimation.\n",
    "    \"\"\"\n",
    "    diff = rul_pred - rul_true\n",
    "    return np.sum(np.where(diff < 0, np.exp(-diff/13)-1, np.exp(diff/10)-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200dbf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train_reduced, y_train)\n",
    "y_pred_lr = lr.predict(X_test_reduced)\n",
    "\n",
    "# S-метрика на тесте\n",
    "s_score = compute_s_score(y_test.values, y_pred_lr)\n",
    "print(\"S-score LinearRegression:\", s_score)\n",
    "print(\"LinearRegression MAE:\", mean_absolute_error(y_test, y_pred_lr))\n",
    "\n",
    "# Кросс-валидация по S-метрике\n",
    "s_score_scorer = make_scorer(compute_s_score, greater_is_better=False)\n",
    "cv_scores_s_lr = cross_val_score(\n",
    "    lr, X_train_reduced, y_train, cv=5, scoring=s_score_scorer\n",
    ")\n",
    "print(\"Средний S-score LinearRegression по CV:\", -cv_scores_s_lr.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2801c8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(y_test, y_pred_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf47d2d",
   "metadata": {},
   "source": [
    "## 6. Baseline XGBoost Model\n",
    "\n",
    "- We will train a simple XGBoost model to predict RUL. We use only the rolling window features, derivatives, and PCA features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd6db96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "model_xgb = xgb.XGBRegressor(n_estimators=1000, max_depth=5, learning_rate=0.1, random_state=42, n_jobs=-1)\n",
    "model_xgb.fit(X_train_reduced, y_train)\n",
    "y_pred_xgb = model_xgb.predict(X_test_reduced)\n",
    "\n",
    "\n",
    "s_score_scorer = make_scorer(compute_s_score, greater_is_better=False)\n",
    "cv_scores_s = cross_val_score(\n",
    "    model_xgb, X_train_reduced, y_train, cv=5, scoring=s_score_scorer\n",
    ")\n",
    "print(\"Средний S-score по CV:\", -cv_scores_s.mean())\n",
    "\n",
    "# S-метрика на тесте\n",
    "s_score = compute_s_score(y_test.values, y_pred_xgb)\n",
    "print(\"S-score XGBRegressor:\", s_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f24df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(y_test, y_pred_xgb)\n",
    "plot_feature_importances(model_xgb, X_train_reduced)\n",
    "plot_shap_values(model_xgb, X_test_reduced)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34523283",
   "metadata": {},
   "source": [
    "# 7. Baseline Catboost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306b56dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CatBoost\n",
    "\n",
    "model_cat = CatBoostRegressor(\n",
    "    early_stopping_rounds=50, iterations=1000, learning_rate=0.1, depth=5, random_seed=42, verbose=100\n",
    ")\n",
    "\n",
    "# Cross - validation\n",
    "s_score_scorer = make_scorer(compute_s_score, greater_is_better=False)\n",
    "\n",
    "cv_scores_s_cat = cross_val_score(\n",
    "    model_cat, X_train_reduced, y_train, cv=5, scoring=s_score_scorer\n",
    ")\n",
    "print(\"Средний S-score CatBoost по CV:\", -cv_scores_s_cat.mean())\n",
    "\n",
    "model_cat.fit(X_train_reduced, y_train)\n",
    "y_pred_cat = model_cat.predict(X_test_reduced)\n",
    "s_score_cat = compute_s_score(y_test.values, y_pred_cat)\n",
    "print(\"S-score CatBoost:\", s_score_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9bd6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(y_test, y_pred_cat)\n",
    "plot_feature_importances_catboost(model_cat, X_train_reduced)\n",
    "plot_shap_values(model_cat, X_test_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e778d8",
   "metadata": {},
   "source": [
    "Our graph shows the following:  \n",
    "  \n",
    "The average error (red dotted line) is negative, i.e. the model overestimates the remaining service life on average (predicts more than it actually is).  \n",
    "  \n",
    "Distribution of errors - most errors are in the range from -10 to 10, but there is a long left tail (errors up to -50), i.e. sometimes the model is very wrong in the direction of overestimating the service life.  \n",
    "  \n",
    "Practical conclusion:  \n",
    "The model tends to be \"optimistic\" - it often believes that the engine will last longer than it actually does. This is dangerous for operation, since you may not have time to replace or service the engine in time.\n",
    "Recommendation:  \n",
    "It is worth refining the model or adding a penalty for overestimating the service life to reduce the negative bias of the error.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
